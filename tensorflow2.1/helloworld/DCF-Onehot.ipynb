{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "Width=224                                     #256\n",
    "Hight=224\n",
    "dataset_dir = \"./data/dc_3000/\"\n",
    "train_dir = dataset_dir + \"train\"\n",
    "valid_dir = dataset_dir + \"val\"\n",
    "save_model_dir = \"./weight/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "train_image_path = glob.glob(train_dir+\"/*/*.jpg\")\n",
    "valid_image_path = glob.glob(valid_dir+\"/*/*.jpg\")\n",
    "# print(train_image_path)\n",
    "# print(valid_image_path)\n",
    "print(len(train_image_path))\n",
    "print(len(valid_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image,channels=3)\n",
    "    image = tf.image.resize(image,[Width,Hight])\n",
    "\n",
    "    # 数据增强 -- 随机裁剪\n",
    "    #image = tf.image.random_crop(image,[256,256,3])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    # image = tf.image.random_brightness(image,0.5)\n",
    "    # image = tf.image.random_contrast(image,0.3 ,1)\n",
    "\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image = image/255\n",
    "    label = tf.reshape(label,[1])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_valid_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image,channels=3)\n",
    "    image = tf.image.resize(image,[Width,Hight])\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image = image/255\n",
    "    label = tf.reshape(label,[1])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make traindata && label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. ... 2. 2. 2.], shape=(3000,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_image_label = [int((p.split(\"\\\\\")[1]))for p in train_image_path]    #only label\n",
    "#train_image_label = [tf.one_hot(int((p.split(\"\\\\\")[1])),3,on_value=1,off_value=None,axis=0)for p in train_image_path]  #one-hot\n",
    "train_image_label = tf.cast(train_image_label,tf.float32)\n",
    "print(train_image_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = len(train_image_path)\n",
    "\n",
    "train_image_ds = tf.data.Dataset.from_tensor_slices((train_image_path,train_image_label)) # 组合\n",
    "train_image_ds = train_image_ds.map(load_preprocess_image)  # map\n",
    "train_image_ds = train_image_ds.shuffle(train_count).batch(BATCH_SIZE)# shuffle && batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img,label in train_image_ds.take(1):\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_image_label = [int((p.split(\"\\\\\")[1]))for p in valid_image_path]    #only label\n",
    "# valid_image_label = [tf.one_hot(int((p.split(\"\\\\\")[1])),3,on_value=1,off_value=None,axis=0)for p in valid_image_path] #one-hot\n",
    "valid_image_label = tf.cast(valid_image_label,tf.float32)\n",
    "valid_count = len(valid_image_path)\n",
    "\n",
    "valid_image_ds = tf.data.Dataset.from_tensor_slices((valid_image_path,valid_image_label))     #组合\n",
    "valid_image_ds = valid_image_ds.map(load_preprocess_valid_image)#map\n",
    "valid_image_ds = valid_image_ds.shuffle(valid_count).batch(BATCH_SIZE)    # shuffle && batch\n",
    "valid_image_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img,label in valid_image_ds.take(1):\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), input_shape=(256, 256, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(3),\n",
    "#     tf.keras.layers.Activation('softmax', dtype='float32')\n",
    "# ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[244,244]\n",
    "# import resnet_model\n",
    "# model = resnet_model.resnet50(\n",
    "#         num_classes = 3,\n",
    "#         use_l2_regularizer = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 134,272,835\n",
      "Trainable params: 134,272,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.vgg16 import VGG16\n",
    "model = VGG16(3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #[244,244]\n",
    "#from resnet_model3 import ResNet18\n",
    "#model = ResNet18([2, 2, 2, 2])\n",
    "\n",
    "# from models.resnet_model3 import resnet_18\n",
    "# model=resnet_18()\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "#               metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.resnet import resnet_18\n",
    "# model = resnet_18()\n",
    "# model.build(input_shape=(None, 224, 224, 3))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_image_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3)\n",
      "tf.Tensor([0.35845077 0.35123852 0.29031074], shape=(3,), dtype=float32)\n",
      "[0.35845077 0.35123852 0.29031074] None\n",
      "tf.Tensor([2.], shape=(1,), dtype=float32)\n",
      "[2.] None\n"
     ]
    }
   ],
   "source": [
    "pred = model(imgs)\n",
    "print(pred.shape)\n",
    "print(pred[0].numpy(),print(pred[0]))\n",
    "print(labels[0].numpy(),print(labels[0]))\n",
    "# print(np.array([p[0].numpy() for p in tf.cast(pred>0,tf.int32)]))\n",
    "# print(np.array([l[0].numpy() for l in labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adadelta()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(y_true=labels, y_pred=predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def valid_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    v_loss = loss_object(labels, predictions)\n",
    "\n",
    "    valid_loss(v_loss)\n",
    "    valid_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adadelta() #Adam()  SGD()\n",
    "# loss_object =tf.keras.losses.SparseCategoricalCrossentropy() #BinaryCrossentropy()\n",
    "# train_loss = tf.keras.metrics.Mean(\"train_loss\")\n",
    "# train_accuracy = tf.keras.metrics.SparseCategoricalCrossentropy() #Accuracy() CategoricalAccuracy() SparseCategoricalCrossentropy()\n",
    "# valid_loss = tf.keras.metrics.Mean(\"valid_loss\")\n",
    "# valid_accuracy = tf.keras.metrics.SparseCategoricalCrossentropy() #Accuracy() CategoricalAccuracy() SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_step(images, labels):\n",
    "#     with tf.GradientTape() as t:\n",
    "#         pred = model(images,training=True)\n",
    "#         #loss_step = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels, pred)\n",
    "#         loss_step = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(labels, pred)  # 这里参数的意思是没有激活\n",
    "#     grads = t.gradient(loss_step, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "#     train_loss(loss_step)\n",
    "#     train_accuracy(labels,pred)\n",
    "#     #print(labels)\n",
    "#     #print(pred)\n",
    "\n",
    "# def valid_step(images, labels):\n",
    "#     pred = model(images,training=False)\n",
    "#     #loss_step = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels, pred)  # 这里参数的意思是没有激活\n",
    "#     loss_step = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(labels, pred)  # 这里参数的意思是没有激活\n",
    "#     valid_loss(loss_step)\n",
    "#     valid_accuracy(labels,pred)\n",
    "#     #print(labels)\n",
    "#     #print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1;loss1.099,accuracy:0.370,valid_loss:1.098,valid_accuracy:0.454;\n",
      "Train Epoch:2;loss1.098,accuracy:0.385,valid_loss:1.098,valid_accuracy:0.446;\n",
      "Train Epoch:3;loss1.098,accuracy:0.400,valid_loss:1.098,valid_accuracy:0.451;\n",
      "Train Epoch:4;loss1.098,accuracy:0.407,valid_loss:1.098,valid_accuracy:0.458;\n",
      "Train Epoch:5;loss1.098,accuracy:0.423,valid_loss:1.098,valid_accuracy:0.459;\n",
      "Train Epoch:6;loss1.098,accuracy:0.426,valid_loss:1.098,valid_accuracy:0.478;\n",
      "Train Epoch:7;loss1.098,accuracy:0.434,valid_loss:1.098,valid_accuracy:0.488;\n",
      "Train Epoch:8;loss1.098,accuracy:0.441,valid_loss:1.098,valid_accuracy:0.495;\n",
      "Train Epoch:9;loss1.098,accuracy:0.445,valid_loss:1.098,valid_accuracy:0.506;\n",
      "Train Epoch:10;loss1.098,accuracy:0.451,valid_loss:1.098,valid_accuracy:0.508;\n",
      "Train Epoch:11;loss1.097,accuracy:0.455,valid_loss:1.097,valid_accuracy:0.538;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a0df46c8bd6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimgs_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_image_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mvalid_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Space.Develop\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 定义四个个空列表进行每一个epoch的记录\n",
    "EPOCHS=1000\n",
    "train_loss_result = []\n",
    "train_acc_result = []\n",
    "valid_loss_result = []\n",
    "valid_acc_result = []\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for imgs_,labels_ in train_image_ds:\n",
    "        train_step(imgs_, labels_)\n",
    "    \n",
    "\n",
    "    train_loss_result.append(train_loss.result())\n",
    "    train_acc_result.append(train_accuracy.result())\n",
    "    \n",
    "    for imgs_,labels_ in valid_image_ds:\n",
    "        valid_step(imgs_, labels_)\n",
    "\n",
    "\n",
    "    valid_loss_result.append(valid_loss.result())\n",
    "    valid_acc_result.append(valid_accuracy.result())\n",
    "\n",
    "    print(f'Train Epoch:{epoch+1};loss{train_loss.result():.3f},accuracy:{train_accuracy.result():.3f},valid_loss:{valid_loss.result():.3f},valid_accuracy:{valid_accuracy.result():.3f};')\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "EPOCHS=1000\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    step = 0\n",
    "    for images, labels in train_image_ds:\n",
    "        step += 1\n",
    "        train_step(images, labels)\n",
    "        print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n",
    "                                                                                 EPOCHS,\n",
    "                                                                                 step,\n",
    "                                                                                 math.ceil(train_count / BATCH_SIZE),\n",
    "                                                                                 train_loss.result(),\n",
    "                                                                                 train_accuracy.result()))\n",
    "\n",
    "    for valid_images, valid_labels in valid_image_ds:\n",
    "        valid_step(valid_images, valid_labels)\n",
    "\n",
    "    print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n",
    "          \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n",
    "                                                              EPOCHS,\n",
    "                                                              train_loss.result(),\n",
    "                                                              train_accuracy.result(),\n",
    "                                                              valid_loss.result(),\n",
    "                                                              valid_accuracy.result()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./weight//fashion_mnist.h5\n"
     ]
    }
   ],
   "source": [
    "# model.save_weights(filepath=save_model_dir, save_format='tf')\n",
    "\n",
    "model_path = save_model_dir+\"/fashion_mnist.h5\"\n",
    "print(model_path)\n",
    "model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
