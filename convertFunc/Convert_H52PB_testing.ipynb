{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "output_1 is not in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-acdc781aaa73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m#  加载模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mh5_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mh5_to_pb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_graph_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-acdc781aaa73>\u001b[0m in \u001b[0;36mh5_to_pb\u001b[1;34m(h5_model, output_dir, model_name, out_prefix, log_tensorboard)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# 写入pb模型文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0minit_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mmain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mgraph_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# 输出日志文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[1;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;31m# This graph only includes the nodes needed to evaluate the output nodes, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;31m# removes unneeded nodes like those involved in saving and assignment.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m   \u001b[0minference_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_sub_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;31m# Identify the ops in the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36mextract_sub_graph\u001b[1;34m(graph_def, dest_nodes)\u001b[0m\n\u001b[0;32m    193\u001b[0m   name_to_input_name, name_to_node, name_to_seq_num = _extract_graph_summary(\n\u001b[0;32m    194\u001b[0m       graph_def)\n\u001b[1;32m--> 195\u001b[1;33m   \u001b[0m_assert_nodes_are_present\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_to_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m   \u001b[0mnodes_to_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bfs_for_reachable_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_to_input_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36m_assert_nodes_are_present\u001b[1;34m(name_to_node, nodes)\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;34m\"\"\"Assert that nodes are present in the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname_to_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s is not in graph\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: output_1 is not in graph"
     ]
    }
   ],
   "source": [
    "#*-coding:utf-8-*\n",
    "\n",
    "\"\"\"\n",
    "将keras的.h5的模型文件，转换成TensorFlow的pb文件\n",
    "\"\"\"\n",
    "# ==========================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "def h5_to_pb(h5_model, output_dir, model_name, out_prefix=\"output_\", log_tensorboard=True):\n",
    "    \"\"\".h5模型文件转换成pb模型文件\n",
    "    Argument:\n",
    "        h5_model: str\n",
    "            .h5模型文件\n",
    "        output_dir: str\n",
    "            pb模型文件保存路径\n",
    "        model_name: str\n",
    "            pb模型文件名称\n",
    "        out_prefix: str\n",
    "            根据训练，需要修改\n",
    "        log_tensorboard: bool\n",
    "            是否生成日志文件\n",
    "    Return:\n",
    "        pb模型文件\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_dir) == False:\n",
    "        os.mkdir(output_dir)\n",
    "    out_nodes = []\n",
    "    for i in range(len(h5_model.outputs)):\n",
    "        out_nodes.append(out_prefix + str(i + 1))\n",
    "        tf.identity(h5_model.output[i], out_prefix + str(i + 1))\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "    from tensorflow.python.framework import graph_util, graph_io\n",
    "    # 写入pb模型文件\n",
    "    init_graph = sess.graph.as_graph_def()\n",
    "    main_graph = graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)\n",
    "    graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=False)\n",
    "    # 输出日志文件\n",
    "    if log_tensorboard:\n",
    "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "        import_pb_to_tensorboard.import_to_tensorboard(os.path.join(output_dir, model_name), output_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #  .h模型文件路径参数\n",
    "    input_path = \"./model/\"\n",
    "    weight_file = 'mmmmmm.h5'\n",
    "    weight_file_path = os.path.join(input_path, weight_file)\n",
    "    output_graph_name = weight_file[:-3] + '.pb'\n",
    "\n",
    "    #  pb模型文件输出输出路径\n",
    "    output_dir = os.path.join(os.getcwd(), \"./frozen_models/\")\n",
    "\n",
    "    #  加载模型\n",
    "    h5_model = tf.keras.models.load_model(weight_file_path)\n",
    "    h5_to_pb(h5_model, output_dir=output_dir, model_name=output_graph_name)\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-input_fld INPUT_FLD]\n",
      "                             [-output_fld OUTPUT_FLD]\n",
      "                             [-input_model_file INPUT_MODEL_FILE]\n",
      "                             [-output_model_file OUTPUT_MODEL_FILE]\n",
      "                             [-output_graphdef_file OUTPUT_GRAPHDEF_FILE]\n",
      "                             [-num_outputs NUM_OUTPUTS] [-graph_def GRAPH_DEF]\n",
      "                             [-output_node_prefix OUTPUT_NODE_PREFIX]\n",
      "                             [-quantize QUANTIZE]\n",
      "                             [-theano_backend THEANO_BACKEND] [-f F]\n",
      "\n",
      "set input arguments\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -input_fld INPUT_FLD\n",
      "  -output_fld OUTPUT_FLD\n",
      "  -input_model_file INPUT_MODEL_FILE\n",
      "  -output_model_file OUTPUT_MODEL_FILE\n",
      "  -output_graphdef_file OUTPUT_GRAPHDEF_FILE\n",
      "  -num_outputs NUM_OUTPUTS\n",
      "  -graph_def GRAPH_DEF\n",
      "  -output_node_prefix OUTPUT_NODE_PREFIX\n",
      "  -quantize QUANTIZE\n",
      "  -theano_backend THEANO_BACKEND\n",
      "  -f F\n",
      "input args:  Namespace(f='C:\\\\Users\\\\li970\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-5e6b0699-b629-41b2-a617-d98629f409a7.json', graph_def=False, input_fld='.', input_model_file='./model/mmmmmm.h5', num_outputs=1, output_fld='', output_graphdef_file='model.ascii', output_model_file='./model/XXXXX.pb', output_node_prefix='output_node', quantize=False, theano_backend=False)\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Input nodes names are:  ['conv2d_input_3']\n",
      "Output nodes names are:  ['output_class_3/Identity']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "output_class_3/Identity is not in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-94d1babab54b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mconstant_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_node_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mconstant_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_node_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[0mgraph_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstant_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_fld\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_model_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved the freezed graph (ready for inference) at: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_fld\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_model_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[1;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;31m# This graph only includes the nodes needed to evaluate the output nodes, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;31m# removes unneeded nodes like those involved in saving and assignment.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m   \u001b[0minference_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_sub_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;31m# Identify the ops in the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36mextract_sub_graph\u001b[1;34m(graph_def, dest_nodes)\u001b[0m\n\u001b[0;32m    193\u001b[0m   name_to_input_name, name_to_node, name_to_seq_num = _extract_graph_summary(\n\u001b[0;32m    194\u001b[0m       graph_def)\n\u001b[1;32m--> 195\u001b[1;33m   \u001b[0m_assert_nodes_are_present\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_to_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m   \u001b[0mnodes_to_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bfs_for_reachable_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_to_input_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36m_assert_nodes_are_present\u001b[1;34m(name_to_node, nodes)\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;34m\"\"\"Assert that nodes are present in the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname_to_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s is not in graph\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: output_class_3/Identity is not in graph"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='set input arguments')\n",
    "parser.add_argument('-input_fld', action=\"store\", \n",
    "                    dest='input_fld', type=str, default='.')\n",
    "parser.add_argument('-output_fld', action=\"store\", \n",
    "                    dest='output_fld', type=str, default='')\n",
    "parser.add_argument('-input_model_file', action=\"store\", \n",
    "                    dest='input_model_file', type=str, default='./model/mmmmmm.h5')  # 输入\n",
    "parser.add_argument('-output_model_file', action=\"store\", \n",
    "                    dest='output_model_file', type=str, default='./model/XXXXX.pb') # 输出\n",
    "parser.add_argument('-output_graphdef_file', action=\"store\", \n",
    "                    dest='output_graphdef_file', type=str, default='model.ascii')\n",
    "parser.add_argument('-num_outputs', action=\"store\", \n",
    "                    dest='num_outputs', type=int, default=1)\n",
    "parser.add_argument('-graph_def', action=\"store\", \n",
    "                    dest='graph_def', type=bool, default=False)\n",
    "parser.add_argument('-output_node_prefix', action=\"store\", \n",
    "                    dest='output_node_prefix', type=str, default='output_node')\n",
    "parser.add_argument('-quantize', action=\"store\", \n",
    "                    dest='quantize', type=bool, default=False)\n",
    "parser.add_argument('-theano_backend', action=\"store\", \n",
    "                    dest='theano_backend', type=bool, default=False)\n",
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()\n",
    "parser.print_help()\n",
    "print('input args: ', args)\n",
    "\n",
    "if args.theano_backend is True and args.quantize is True:\n",
    "    raise ValueError(\"Quantize feature does not work with theano backend.\")\n",
    "\n",
    "\n",
    "# initialize\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "output_fld =  args.input_fld if args.output_fld == '' else args.output_fld\n",
    "if args.output_model_file == '':\n",
    "    args.output_model_file = str(Path(args.input_model_file).name) + '.pb'\n",
    "Path(output_fld).mkdir(parents=True, exist_ok=True)    \n",
    "weight_file_path = str(Path(args.input_fld) / args.input_model_file)\n",
    "\n",
    "\n",
    "# Load keras model and rename output\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "if args.theano_backend:\n",
    "    K.set_image_data_format('channels_first')\n",
    "else:\n",
    "    K.set_image_data_format('channels_last')\n",
    "\n",
    "try:\n",
    "    net_model = load_model(weight_file_path)\n",
    "except ValueError as err:\n",
    "    print('''Input file specified ({}) only holds the weights, and not the model defenition.\n",
    "    Save the model using mode.save(filename.h5) which will contain the network architecture\n",
    "    as well as its weights. \n",
    "    If the model is saved using model.save_weights(filename.h5), the model architecture is \n",
    "    expected to be saved separately in a json format and loaded prior to loading the weights.\n",
    "    Check the keras documentation for more details (https://keras.io/getting-started/faq/)'''\n",
    "          .format(weight_file_path))\n",
    "    raise err\n",
    "# num_output = args.num_outputs\n",
    "# pred = [None]*num_output\n",
    "# pred_node_names = [None]*num_output\n",
    "# for i in range(num_output):\n",
    "#     pred_node_names[i] = args.output_node_prefix+str(i)\n",
    "#     pred[i] = tf.identity(net_model.outputs[i], name=pred_node_names[i])\n",
    "# num_output =  len(net_model.output_names)\n",
    "# pred_node_names = [None]*num_output\n",
    "# pred = [None]*num_output\n",
    "# # pred_node_names = net_model.output_names\n",
    "# for i in range(num_output):\n",
    "#     pred_node_names[i] = args.output_node_prefix+str(i)\n",
    "#     pred[i] = tf.identity(net_model.outputs[i], name=pred_node_names[i])\n",
    "input_node_names = [node.op.name for node in net_model.inputs]\n",
    "print('Input nodes names are: ', input_node_names)\n",
    "pred_node_names = [node.op.name for node in net_model.outputs]\n",
    "print('Output nodes names are: ', pred_node_names)\n",
    "\n",
    "# print(\"net_model.input.op.name:\", net_model.input.op.name)\n",
    "# print(\"net_model.output.op.name:\", net_model.output.op.name)\n",
    "# print(\"net_model.input_names:\", net_model.input_names)\n",
    "# print(\"net_model.output_names:\", net_model.output_names)\n",
    "\n",
    "# [optional] write graph definition in ascii\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "if args.graph_def:\n",
    "    f = args.output_graphdef_file \n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), output_fld, f, as_text=True)\n",
    "    print('saved the graph definition in ascii format at: ', str(Path(output_fld) / f))\n",
    "\n",
    "\n",
    "# convert variables to constants and save\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "if args.quantize:\n",
    "    from tensorflow.tools.graph_transforms import TransformGraph\n",
    "    transforms = [\"quantize_weights\", \"quantize_nodes\"]\n",
    "    transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [], pred_node_names, transforms)\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, transformed_graph_def, pred_node_names)\n",
    "else:\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)    \n",
    "graph_io.write_graph(constant_graph, output_fld, args.output_model_file, as_text=False)\n",
    "print('saved the freezed graph (ready for inference) at: ', str(Path(output_fld) / args.output_model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, None, None, 16)    160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 32)    4640      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_class (Dense)         (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 5,130\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "Input\n",
      "sequential/conv2d/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d/Conv2D/ReadVariableOp\n",
      "sequential/conv2d/Conv2D\n",
      "sequential/conv2d/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d/BiasAdd\n",
      "sequential/conv2d/Relu\n",
      "sequential/conv2d_1/Conv2D/ReadVariableOp/resource\n",
      "sequential/conv2d_1/Conv2D/ReadVariableOp\n",
      "sequential/conv2d_1/Conv2D\n",
      "sequential/conv2d_1/BiasAdd/ReadVariableOp/resource\n",
      "sequential/conv2d_1/BiasAdd/ReadVariableOp\n",
      "sequential/conv2d_1/BiasAdd\n",
      "sequential/conv2d_1/Relu\n",
      "sequential/global_average_pooling2d/Mean/reduction_indices\n",
      "sequential/global_average_pooling2d/Mean\n",
      "sequential/output_class/MatMul/ReadVariableOp/resource\n",
      "sequential/output_class/MatMul/ReadVariableOp\n",
      "sequential/output_class/MatMul\n",
      "sequential/output_class/BiasAdd/ReadVariableOp/resource\n",
      "sequential/output_class/BiasAdd/ReadVariableOp\n",
      "sequential/output_class/BiasAdd\n",
      "sequential/output_class/Softmax\n",
      "Identity\n",
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'Input:0' shape=(None, None, None, 1) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(None, 10) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    " \n",
    "def convert_h5to_pb():\n",
    "    model = tf.keras.models.load_model(\"./model/mmmmmm.h5\",compile=False)\n",
    "    model.summary()\n",
    "    full_model = tf.function(lambda Input: model(Input))\n",
    "    full_model = full_model.get_concrete_function(tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    " \n",
    "    # Get frozen ConcreteFunction\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    frozen_func.graph.as_graph_def()\n",
    " \n",
    "    layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    " \n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model inputs: \")\n",
    "    print(frozen_func.inputs)\n",
    "    print(\"Frozen model outputs: \")\n",
    "    print(frozen_func.outputs)\n",
    " \n",
    "    # Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                      logdir=\"./frozen_models\",\n",
    "                      name=\"nnnnnn.pb\",\n",
    "                      as_text=False)\n",
    "convert_h5to_pb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
